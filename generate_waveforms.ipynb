{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from starccato_flow.data.ccsn_data import CCSNData\n",
    "from starccato_flow.data.toy_data import ToyData\n",
    "from starccato_flow.training.trainer_vae import VAETrainer\n",
    "from starccato_flow.training.trainer_cvae import ConditionalVAETrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccsn_dataset = CCSNData(noise=True, curriculum=False)\n",
    "ccsn_dataset.plot_signal_distribution(background=\"black\", font_family=\"sans-serif\", font_name=\"Avenir\", fname=\"plots/ccsn_signal_distribution.svg\")\n",
    "\n",
    "toy_dataset = ToyData(noise=False, curriculum=False)\n",
    "toy_dataset.plot_signal_distribution(background=\"black\", font_family=\"sans-serif\", font_name=\"Avenir\", fname=\"plots/toy_signal_distribution.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ConditionalVAETrainer(\n",
    "    toy=False, \n",
    "    num_epochs=256,\n",
    "    noise=False, \n",
    "    curriculum=False,\n",
    "    validation_split=0.1,\n",
    "    noise_realizations=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8621206",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from starccato_flow.utils.defaults import DEVICE\n",
    "\n",
    "# Test: Generate signals with DIFFERENT parameter values\n",
    "print(\"Testing CVAE parameter conditioning...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define 3 different parameter sets\n",
    "if trainer.param_dim == 1:\n",
    "    param_sets = [\n",
    "        np.array([0.02]),   # Low beta\n",
    "        np.array([0.10]),   # Medium beta\n",
    "        np.array([0.18])    # High beta\n",
    "    ]\n",
    "    param_labels = ['β=0.02', 'β=0.10', 'β=0.18']\n",
    "elif trainer.param_dim == 4:\n",
    "    param_sets = [\n",
    "        np.array([0.02, 6.0, 3000.0, 0.10]),   # Low values\n",
    "        np.array([0.10, 10.0, 6000.0, 0.15]),  # Medium values\n",
    "        np.array([0.18, 14.0, 9000.0, 0.20])   # High values\n",
    "    ]\n",
    "    param_labels = ['Low', 'Medium', 'High']\n",
    "else:\n",
    "    param_sets = [np.zeros(trainer.param_dim) for _ in range(3)]\n",
    "    param_labels = ['Set 1', 'Set 2', 'Set 3']\n",
    "\n",
    "# Normalize parameters\n",
    "param_sets_norm = [trainer.training_dataset.normalize_parameters(p) for p in param_sets]\n",
    "\n",
    "# Generate noise samples ONCE (will be reused for all parameter sets)\n",
    "num_samples_per_set = 3\n",
    "z_samples = torch.randn(num_samples_per_set, trainer.z_dim).to(DEVICE)\n",
    "print(f\"\\nUsing {num_samples_per_set} shared noise samples across all parameter sets\")\n",
    "\n",
    "trainer.cvae.eval()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "\n",
    "# First pass: generate all signals and find global y-limits\n",
    "all_signals_scaled = []\n",
    "with torch.no_grad():\n",
    "    for i, (params_norm, params_raw, label) in enumerate(zip(param_sets_norm, param_sets, param_labels)):\n",
    "        # Use the SAME z_samples for all parameter sets\n",
    "        params_tensor = torch.tensor(params_norm, dtype=torch.float32).unsqueeze(0).repeat(num_samples_per_set, 1).to(DEVICE)\n",
    "        \n",
    "        generated = trainer.cvae.decoder(z_samples, params_tensor).cpu().numpy()\n",
    "        \n",
    "        for j in range(num_samples_per_set):\n",
    "            signal_denorm = trainer.training_dataset.denormalise_signals(generated[j])\n",
    "            signal_scaled = signal_denorm / 1e-20\n",
    "            all_signals_scaled.append(signal_scaled)\n",
    "\n",
    "# Calculate global y-limits\n",
    "all_signals_array = np.array(all_signals_scaled)\n",
    "y_min = all_signals_array.min()\n",
    "y_max = all_signals_array.max()\n",
    "y_margin = (y_max - y_min) * 0.1\n",
    "\n",
    "# Second pass: plot with consistent y-limits\n",
    "idx = 0\n",
    "with torch.no_grad():\n",
    "    for i, (params_norm, params_raw, label) in enumerate(zip(param_sets_norm, param_sets, param_labels)):\n",
    "        for j in range(num_samples_per_set):\n",
    "            signal_scaled = all_signals_scaled[idx]\n",
    "            time = np.arange(len(signal_scaled)) / 16384\n",
    "            \n",
    "            axes[i, j].plot(time, signal_scaled, linewidth=0.8, color='#2c3e50')\n",
    "            axes[i, j].set_ylabel('Strain (×10⁻²⁰)', fontsize=9)\n",
    "            axes[i, j].set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "            axes[i, j].grid(True, alpha=0.3)\n",
    "            axes[i, j].axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "            \n",
    "            if i == 0:\n",
    "                axes[i, j].set_title(f'Noise Sample {j+1}', fontsize=10)\n",
    "            if i == 2:\n",
    "                axes[i, j].set_xlabel('Time (s)', fontsize=9)\n",
    "            if j == 0:\n",
    "                if trainer.param_dim == 1:\n",
    "                    axes[i, j].text(-0.3, 0.5, label, transform=axes[i, j].transAxes, \n",
    "                                   fontsize=11, va='center', rotation=90, weight='bold')\n",
    "                else:\n",
    "                    param_str = f\"β={params_raw[0]:.2f}\\nω={params_raw[1]:.1f}\"\n",
    "                    axes[i, j].text(-0.35, 0.5, param_str, transform=axes[i, j].transAxes, \n",
    "                                   fontsize=9, va='center', rotation=90)\n",
    "            \n",
    "            idx += 1\n",
    "\n",
    "plt.suptitle('CVAE Generation Test: Same Noise, Different Parameters', fontsize=14, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/cvae_parameter_test.svg', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ If the model is learning parameters correctly:\")\n",
    "print(\"  - Each COLUMN should show consistent structure (same noise)\")\n",
    "print(\"  - Different ROWS should look different (different parameters)\")\n",
    "print(\"  - Signals in same column vary due to parameter changes, not noise\")\n",
    "print(\"\\nIf all signals look too similar → model NOT learning parameters\")\n",
    "print(\"If columns show inconsistent structure → check noise reuse logic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ========== CHOOSE YOUR TARGET PARAMETER VALUES HERE ==========\n",
    "target_beta = 0.05    # Beta value\n",
    "target_omega = None    # Set to a value like 10.0 for omega, or None to ignore\n",
    "# ================================================================\n",
    "\n",
    "# Get parameters from training dataset\n",
    "params = trainer.training_dataset.parameters\n",
    "num_params = params.shape[1]\n",
    "param_names = trainer.training_dataset.parameter_names\n",
    "\n",
    "print(f\"Dataset has {num_params} parameter(s): {param_names}\")\n",
    "\n",
    "# Build target vector based on available parameters\n",
    "if num_params == 1:\n",
    "    # Only beta available\n",
    "    target_vector = np.array([target_beta])\n",
    "    print(f\"\\nSearching for signals near: β = {target_beta:.6f}\")\n",
    "elif num_params == 4:\n",
    "    # Beta, omega, A, Ye available\n",
    "    if target_omega is None:\n",
    "        print(\"\\nNote: You have 4 parameters but target_omega is None. Finding signals with similar beta only.\")\n",
    "        # Find signals with closest beta\n",
    "        beta_values = params[:, 0]\n",
    "        differences = np.abs(beta_values - target_beta)\n",
    "        closest_indices = np.argsort(differences)[:2]\n",
    "    else:\n",
    "        # Match on both beta and omega\n",
    "        target_vector = np.array([target_beta, target_omega, 0.0, 0.0])  # A and Ye set to 0 for now\n",
    "        print(f\"\\nSearching for signals near: β = {target_beta:.6f}, ω₀ = {target_omega:.6f}\")\n",
    "        # Calculate Euclidean distance for beta and omega only\n",
    "        differences = np.sqrt((params[:, 0] - target_beta)**2 + (params[:, 1] - target_omega)**2)\n",
    "        closest_indices = np.argsort(differences)[:2]\n",
    "else:\n",
    "    # Use all available parameters\n",
    "    target_vector = np.array([target_beta] + [0.0] * (num_params - 1))\n",
    "    print(f\"\\nSearching for signals near target values\")\n",
    "\n",
    "# For single parameter case\n",
    "if num_params == 1:\n",
    "    differences = np.abs(params[:, 0] - target_beta)\n",
    "    closest_indices = np.argsort(differences)[:2]\n",
    "\n",
    "idx1, idx2 = closest_indices[0], closest_indices[1]\n",
    "\n",
    "# Get the signals\n",
    "signal1, _, param1 = trainer.training_dataset[idx1]\n",
    "signal2, _, param2 = trainer.training_dataset[idx2]\n",
    "\n",
    "# Denormalize for plotting\n",
    "signal1_denorm = trainer.training_dataset.denormalise_signals(signal1.cpu().numpy().flatten())\n",
    "signal2_denorm = trainer.training_dataset.denormalise_signals(signal2.cpu().numpy().flatten())\n",
    "param1_denorm = trainer.training_dataset.denormalize_parameters(param1.cpu().numpy().flatten())\n",
    "param2_denorm = trainer.training_dataset.denormalize_parameters(param2.cpu().numpy().flatten())\n",
    "\n",
    "print(f\"\\nSignal 1 - Index: {idx1}\")\n",
    "print(f\"  β = {param1_denorm[0]:.6f} (Δ = {abs(param1_denorm[0] - target_beta):.6f})\")\n",
    "if num_params == 4 and target_omega is not None:\n",
    "    print(f\"  ω₀ = {param1_denorm[1]:.6f} (Δ = {abs(param1_denorm[1] - target_omega):.6f})\")\n",
    "\n",
    "print(f\"\\nSignal 2 - Index: {idx2}\")\n",
    "print(f\"  β = {param2_denorm[0]:.6f} (Δ = {abs(param2_denorm[0] - target_beta):.6f})\")\n",
    "if num_params == 4 and target_omega is not None:\n",
    "    print(f\"  ω₀ = {param2_denorm[1]:.6f} (Δ = {abs(param2_denorm[1] - target_omega):.6f})\")\n",
    "\n",
    "# Calculate global y-limits for consistent scaling\n",
    "signal1_scaled = signal1_denorm / 1e-20\n",
    "signal2_scaled = signal2_denorm / 1e-20\n",
    "y_min = min(signal1_scaled.min(), signal2_scaled.min())\n",
    "y_max = max(signal1_scaled.max(), signal2_scaled.max())\n",
    "y_margin = (y_max - y_min) * 0.1  # Add 10% margin\n",
    "\n",
    "# Plot the two signals\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "time = np.arange(len(signal1_denorm)) / 16384  # Assuming 16384 Hz sampling rate\n",
    "\n",
    "# Build title strings\n",
    "if num_params == 4 and target_omega is not None:\n",
    "    title1 = f'Signal {idx1}: β = {param1_denorm[0]:.6f}, ω₀ = {param1_denorm[1]:.6f}'\n",
    "    title2 = f'Signal {idx2}: β = {param2_denorm[0]:.6f}, ω₀ = {param2_denorm[1]:.6f}'\n",
    "    suptitle = f'Two Signals Closest to Target β = {target_beta:.6f}, ω₀ = {target_omega:.6f}'\n",
    "else:\n",
    "    title1 = f'Signal {idx1}: β = {param1_denorm[0]:.6f}'\n",
    "    title2 = f'Signal {idx2}: β = {param2_denorm[0]:.6f}'\n",
    "    suptitle = f'Two Signals Closest to Target β = {target_beta:.6f}'\n",
    "\n",
    "axes[0].plot(time, signal1_scaled, linewidth=1, color='#3498db')\n",
    "axes[0].set_ylabel('Strain (×10⁻²⁰)', fontsize=12)\n",
    "axes[0].set_title(title1, fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "axes[0].set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "axes[1].plot(time, signal2_scaled, linewidth=1, color='#e74c3c')\n",
    "axes[1].set_xlabel('Time (s)', fontsize=12)\n",
    "axes[1].set_ylabel('Strain (×10⁻²⁰)', fontsize=12)\n",
    "axes[1].set_title(title2, fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "axes[1].set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "plt.suptitle(suptitle, fontsize=16, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from starccato_flow.utils.defaults import DEVICE\n",
    "\n",
    "# Encode the two signals to latent space\n",
    "with torch.no_grad():\n",
    "    # Get normalized signals (already in normalized form from __getitem__)\n",
    "    signal1_norm = torch.tensor(trainer.training_dataset.normalise_signals(signal1_denorm), dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device=DEVICE)\n",
    "    signal2_norm = torch.tensor(trainer.training_dataset.normalise_signals(signal2_denorm), dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device=DEVICE)\n",
    "\n",
    "    # Encode to latent space\n",
    "    mu1, logvar1 = trainer.vae.encoder(signal1_norm)\n",
    "    mu2, logvar2 = trainer.vae.encoder(signal2_norm)\n",
    "    \n",
    "    # Use mean (mu) for interpolation (not sampling)\n",
    "    z1 = mu1\n",
    "    z2 = mu2\n",
    "    \n",
    "    print(f\"Latent vector 1 shape: {z1.shape}\")\n",
    "    print(f\"Latent vector 2 shape: {z2.shape}\")\n",
    "    \n",
    "    # Interpolate in latent space (midpoint)\n",
    "    z_interpolated = (z1 + z2) / 2.0\n",
    "    \n",
    "    print(f\"Interpolated latent vector shape: {z_interpolated.shape}\")\n",
    "    print(f\"Distance between z1 and z2: {torch.norm(z2 - z1).item():.6f}\")\n",
    "    \n",
    "    # Decode interpolated latent vector\n",
    "    interpolated_signal_norm = trainer.vae.decoder(z_interpolated).cpu().numpy().flatten()\n",
    "    \n",
    "# Denormalize the interpolated signal\n",
    "interpolated_signal = trainer.training_dataset.denormalise_signals(interpolated_signal_norm)\n",
    "\n",
    "# Plot all three signals\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "time = np.arange(len(signal1_denorm)) / 16384\n",
    "\n",
    "# Scale all signals\n",
    "signal1_scaled = signal1_denorm / 1e-20\n",
    "signal2_scaled = signal2_denorm / 1e-20\n",
    "interpolated_scaled = interpolated_signal / 1e-20\n",
    "\n",
    "# Calculate global y-limits for consistent scaling\n",
    "y_min = min(signal1_scaled.min(), signal2_scaled.min(), interpolated_scaled.min())\n",
    "y_max = max(signal1_scaled.max(), signal2_scaled.max(), interpolated_scaled.max())\n",
    "y_margin = (y_max - y_min) * 0.1\n",
    "\n",
    "# Plot signal 1\n",
    "axes[0].plot(time, signal1_scaled, linewidth=1, color='#3498db')\n",
    "axes[0].set_ylabel('Strain (×10⁻²⁰)', fontsize=12)\n",
    "axes[0].set_title(f'Original Signal {idx1}: β = {param1_denorm[0]:.6f}', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "axes[0].set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "# Plot interpolated signal\n",
    "axes[1].plot(time, interpolated_scaled, linewidth=1, color='#2ecc71')\n",
    "axes[1].set_ylabel('Strain (×10⁻²⁰)', fontsize=12)\n",
    "axes[1].set_title(f'Interpolated Signal (Latent Space Midpoint)', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "axes[1].set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "# Plot signal 2\n",
    "axes[2].plot(time, signal2_scaled, linewidth=1, color='#e74c3c')\n",
    "axes[2].set_xlabel('Time (s)', fontsize=12)\n",
    "axes[2].set_ylabel('Strain (×10⁻²⁰)', fontsize=12)\n",
    "axes[2].set_title(f'Original Signal {idx2}: β = {param2_denorm[0]:.6f}', fontsize=14)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "axes[2].set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "plt.suptitle('Latent Space Interpolation Between Two Signals', fontsize=16, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInterpolated signal statistics:\")\n",
    "print(f\"  Min: {interpolated_signal.min():.2e}\")\n",
    "print(f\"  Max: {interpolated_signal.max():.2e}\")\n",
    "print(f\"  Mean: {interpolated_signal.mean():.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1e03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import corner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2b6b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarineccleston/Desktop/starccato/starccato-flow/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/tarineccleston/Desktop/starccato/starccato-flow/src/starccato_flow/data/ccsn_snr_data.py:67: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_candidate_signals' from 'starccato_flow.plotting.plotting' (/Users/tarineccleston/Desktop/starccato/starccato-flow/src/starccato_flow/plotting/plotting.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstarccato_flow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoy_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToyData\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstarccato_flow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mccsn_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CCSNData\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstarccato_flow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mccsn_snr_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CCSNSNRData\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstarccato_flow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstarccato_flow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_reconstruction_distribution, plot_candidate_signal\n",
      "File \u001b[0;32m~/Desktop/starccato/starccato-flow/src/starccato_flow/data/ccsn_snr_data.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fft, ifft\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_candidate_signal, plot_signal_distribution, plot_signal_grid, plot_candidate_signals\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BATCH_SIZE, DEVICE\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SAMPLING_RATE, Y_LENGTH\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_candidate_signals' from 'starccato_flow.plotting.plotting' (/Users/tarineccleston/Desktop/starccato/starccato-flow/src/starccato_flow/plotting/plotting.py)"
     ]
    }
   ],
   "source": [
    "from starccato_flow.data.toy_data import ToyData\n",
    "from starccato_flow.data.ccsn_data import CCSNData\n",
    "from starccato_flow.data.ccsn_snr_data import CCSNSNRData\n",
    "from starccato_flow.training.trainer import Trainer\n",
    "\n",
    "from starccato_flow.plotting.plotting import plot_reconstruction_distribution, plot_candidate_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from starccato_flow.utils.defaults import DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3161a",
   "metadata": {},
   "source": [
    "### Dataset Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccsn_dataset = CCSNSNRData(noise=True, curriculum=False)\n",
    "ccsn_dataset.plot_signal_distribution(background=\"black\", font_family=\"sans-serif\", font_name=\"Avenir\", fname=\"plots/ccsn_signal_distribution.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d44d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccsn_dataset.update_snr(100)\n",
    "# ccsn_dataset.plot_signal_grid(background=\"white\", font_family=\"sans-serif\", font_name=\"Avenir\", fname=\"plots/ccsn_signal_grid.svg\")\n",
    "\n",
    "\n",
    "plot_candidate_signal(\n",
    "    signal=\n",
    "    noisy_signal=\n",
    "    fname=\"plots/ccsn_candidate_signal.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c301ffdb",
   "metadata": {},
   "source": [
    "### Train VAE + Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    toy=toy, \n",
    "    start_snr=200,\n",
    "    end_snr=10,\n",
    "    noise=True, \n",
    "    validation_split=0.1,\n",
    "    curriculum=True,\n",
    "    noise_realizations=1  # Increased from 1 to 3 for more data augmentation\n",
    ")\n",
    "\n",
    "trainer.val_loader.dataset.update_snr(100)\n",
    "index = 0\n",
    "plot_candidate_signal(\n",
    "    signal=trainer.val_loader.dataset.signals[:, index],\n",
    "    noisy_signal=trainer.val_loader.dataset.signals[:, index],\n",
    "    fname=\"plots/ccsn_candidate_signal.svg\"\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33107ed",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0bdbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_generated_signal_distribution(\n",
    "    background=\"white\",\n",
    "    font_family=\"sans-serif\",\n",
    "    font_name=\"Avenir\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1000\n",
    "\n",
    "trainer.val_loader.dataset.update_snr(10)\n",
    "\n",
    "trainer.plot_reconstruction_distribution(\n",
    "    num_samples=1000,\n",
    "    background=\"white\",\n",
    "    font_family=\"sans-serif\",\n",
    "    font_name=\"Avenir\",\n",
    "    index=index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validation_dataset.update_snr(8)\n",
    "trainer.training_dataset.update_snr(8)\n",
    "signal, noisy_signal, params = trainer.training_dataset[1]\n",
    "trainer.plot_corner(signal, noisy_signal, params, index=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 1: Are latent encodings different for different signals?\n",
    "import torch\n",
    "\n",
    "num_test_signals = 5\n",
    "test_indices = [10, 50, 100, 150, 200]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DIAGNOSTIC: Checking Latent Encodings\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "latents = []\n",
    "true_params = []\n",
    "\n",
    "for idx in test_indices:\n",
    "    signal, noisy_signal, params = trainer.validation_dataset[idx]\n",
    "    \n",
    "    # Encode to latent (data is already tensor from dataset)\n",
    "    with torch.no_grad():\n",
    "        if isinstance(noisy_signal, np.ndarray):\n",
    "            noisy_signal_tensor = torch.from_numpy(noisy_signal).unsqueeze(0).to(DEVICE)\n",
    "        else:\n",
    "            noisy_signal_tensor = noisy_signal.unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        _, mean, _ = trainer.vae(noisy_signal_tensor)\n",
    "        mean = mean.view(-1).cpu().numpy()\n",
    "    \n",
    "    latents.append(mean)\n",
    "    \n",
    "    # Convert params to numpy if needed\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        params = params.cpu().numpy()\n",
    "    true_params.append(params.flatten())\n",
    "    \n",
    "    print(f\"\\nSignal {idx}:\")\n",
    "    print(f\"  True params: {params.flatten()}\")\n",
    "    print(f\"  Latent (first 5 dims): {mean[:5]}\")\n",
    "\n",
    "# Check variance in latents\n",
    "latents_array = np.array(latents)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Latent Statistics Across Signals:\")\n",
    "print(f\"  Mean per dimension: {latents_array.mean(axis=0)[:5]}\")\n",
    "print(f\"  Std per dimension:  {latents_array.std(axis=0)[:5]}\")\n",
    "print(f\"  Are latents all the same? {np.allclose(latents_array[0], latents_array[1:], atol=1e-3)}\")\n",
    "\n",
    "# Check variance in true parameters\n",
    "true_params_array = np.array(true_params)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"True Parameter Statistics:\")\n",
    "print(f\"  Mean: {true_params_array.mean(axis=0)}\")\n",
    "print(f\"  Std:  {true_params_array.std(axis=0)}\")\n",
    "print(f\"  Min:  {true_params_array.min(axis=0)}\")\n",
    "print(f\"  Max:  {true_params_array.max(axis=0)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 2: Does the flow produce different posteriors for different latents?\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DIAGNOSTIC: Checking Flow Posterior Predictions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "for i, idx in enumerate(test_indices[:3]):  # Test 3 signals\n",
    "    signal, noisy_signal, params = trainer.training_dataset[idx]\n",
    "    \n",
    "    # Encode to latent (data is already tensor from dataset)\n",
    "    with torch.no_grad():\n",
    "        if isinstance(noisy_signal, np.ndarray):\n",
    "            noisy_signal_tensor = torch.from_numpy(noisy_signal).unsqueeze(0).to(DEVICE)\n",
    "        else:\n",
    "            noisy_signal_tensor = noisy_signal.unsqueeze(0).to(DEVICE)\n",
    "            \n",
    "        _, mean, _ = trainer.vae(noisy_signal_tensor)\n",
    "        z_latent = mean.view(1, -1)\n",
    "        \n",
    "        # Sample from flow conditioned on this latent\n",
    "        samples = trainer.flow.sample(num_samples, context=z_latent).cpu().numpy()\n",
    "        samples = np.exp(samples) - 1e-8  # Reverse log transform\n",
    "    \n",
    "    # Convert params to numpy if needed\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        params = params.cpu().numpy()\n",
    "    \n",
    "    print(f\"\\nSignal {idx}:\")\n",
    "    print(f\"  True params: {params.flatten()}\")\n",
    "    print(f\"  Predicted mean: {samples.mean(axis=0)}\")\n",
    "    print(f\"  Predicted std:  {samples.std(axis=0)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"If predicted means are all similar, flow is NOT conditioning properly!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf532223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 3: Detailed analysis of flow samples\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETAILED DIAGNOSTIC: Flow Sample Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "idx = test_indices[0]  # Test first signal\n",
    "signal, noisy_signal, params = trainer.validation_dataset[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    if isinstance(noisy_signal, np.ndarray):\n",
    "        noisy_signal_tensor = torch.from_numpy(noisy_signal).unsqueeze(0).to(DEVICE)\n",
    "    else:\n",
    "        noisy_signal_tensor = noisy_signal.unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "    _, mean, _ = trainer.vae(noisy_signal_tensor)\n",
    "    z_latent = mean.view(1, -1)\n",
    "    \n",
    "    # Sample from flow\n",
    "    samples = trainer.flow.sample(1000, context=z_latent).cpu().numpy()\n",
    "    \n",
    "    print(f\"\\nSignal {idx}:\")\n",
    "    print(f\"Samples shape: {samples.shape}\")\n",
    "    print(f\"First 5 samples (in log space):\")\n",
    "    for i in range(5):\n",
    "        print(f\"  Sample {i}: {samples[i]}\")\n",
    "    \n",
    "    print(f\"\\nAre all samples identical? {np.allclose(samples[0], samples[1:], atol=1e-6)}\")\n",
    "    print(f\"Std dev across samples: {samples.std(axis=0)}\")\n",
    "    print(f\"Min across samples: {samples.min(axis=0)}\")\n",
    "    print(f\"Max across samples: {samples.max(axis=0)}\")\n",
    "    \n",
    "    # After exp transform\n",
    "    samples_exp = np.exp(samples) - 1e-8\n",
    "    print(f\"\\nAfter exp transform:\")\n",
    "    print(f\"Std dev: {samples_exp.std(axis=0)}\")\n",
    "    print(f\"Mean: {samples_exp.mean(axis=0)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ISSUE: Flow is deterministic - outputting same value every time!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63b43a",
   "metadata": {},
   "source": [
    "### Diagnostic: Check if Flow is Learning Conditional Distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
